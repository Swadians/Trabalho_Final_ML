{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import glob\n",
    "import os\n",
    "\n",
    "def findFiles(path): return glob.glob(path)\n",
    "\n",
    "\n",
    "import unicodedata\n",
    "import string\n",
    "\n",
    "all_letters = string.ascii_letters + \" .,;'\"\n",
    "n_letters = len(all_letters)\n",
    "\n",
    "# Turn a Unicode string to plain ASCII, thanks to http://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in all_letters\n",
    "    )\n",
    "\n",
    "# Build the category_lines dictionary, a list of names per language\n",
    "category_lines = {}\n",
    "all_categories = []\n",
    "\n",
    "all_categories.append(0)\n",
    "all_categories.append(1)\n",
    "\n",
    "n_categories = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Find letter index from all_letters, e.g. \"a\" = 0\n",
    "def letterToIndex(letter):\n",
    "    return all_letters.find(letter)\n",
    "\n",
    "# Just for demonstration, turn a letter into a <1 x n_letters> Tensor\n",
    "def letterToTensor(letter):\n",
    "    tensor = torch.zeros(1, n_letters)\n",
    "    tensor[0][letterToIndex(letter)] = 1\n",
    "    return tensor\n",
    "\n",
    "# Turn a line into a <line_length x 1 x n_letters>,\n",
    "# or an array of one-hot letter vectors\n",
    "def lineToTensor(line):\n",
    "    tensor = torch.zeros(len(line), 1, n_letters)\n",
    "    for li, letter in enumerate(line):\n",
    "        tensor[li][0][letterToIndex(letter)] = 1\n",
    "    return tensor\n",
    "\n",
    "def categoryFromOutput(output):\n",
    "    top_n, top_i = output.topk(1)\n",
    "    category_i = top_i[0].item()\n",
    "    \n",
    "    return all_categories[category_i], category_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "dataCSV = pd.read_csv('data/train.csv', nrows=10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        combined = torch.cat((input, hidden), 1)\n",
    "        hidden = self.i2h(combined)\n",
    "        output = self.i2o(combined)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)\n",
    "\n",
    "n_hidden = 128\n",
    "rnn = RNN(n_letters, n_hidden, n_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.7019, -0.6845]], grad_fn=<LogSoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "input = lineToTensor(dataCSV.iloc[0, 1])\n",
    "hidden = torch.zeros(1, n_hidden)\n",
    "\n",
    "output, next_hidden = rnn(input[0], hidden)\n",
    "print(output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.005 # If you set this too high, it might explode. If too low, it might not learn\n",
    "\n",
    "def train(category_tensor, line_tensor):\n",
    "    hidden = rnn.initHidden()\n",
    "\n",
    "    rnn.zero_grad()\n",
    "\n",
    "    for i in range(line_tensor.size()[0]):\n",
    "        output, hidden = rnn(line_tensor[i], hidden)\n",
    "\n",
    "    loss = criterion(output, category_tensor)\n",
    "    loss.backward()\n",
    "\n",
    "    # Add parameters' gradients to their values, multiplied by learning rate\n",
    "    for p in rnn.parameters():\n",
    "        p.data.add_(-learning_rate, p.grad.data)\n",
    "\n",
    "    return output, loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - 100 1% (0m 6s) 0.3413 (What do physicists, ...) / 0 ✓\n",
      "0 - 200 2% (0m 13s) 0.2122 (Which location is th...) / 0 ✓\n",
      "0 - 300 3% (0m 18s) 0.1530 (What is the largest ...) / 0 ✓\n",
      "0 - 400 4% (0m 20s) 2.3146 (Why did the Pope say...) / 0 ✗ (1)\n",
      "0 - 500 5% (0m 23s) 0.0687 (What are the reasons...) / 0 ✓\n",
      "0 - 600 6% (0m 26s) 0.0544 (Do you know about Mu...) / 0 ✓\n",
      "0 - 700 7% (0m 28s) 0.0344 (Is there anything ca...) / 0 ✓\n",
      "0 - 800 8% (0m 30s) 0.0451 (Why are drain flies ...) / 0 ✓\n",
      "0 - 900 9% (0m 32s) 0.0461 (My skin turns dark w...) / 0 ✓\n",
      "0 - 1000 10% (0m 34s) 0.0467 (What is that one lif...) / 0 ✓\n",
      "0 - 1100 11% (0m 37s) 0.0628 (Why is Niccolò Machi...) / 0 ✓\n",
      "0 - 1200 12% (0m 39s) 0.0743 (What is the scope fo...) / 0 ✓\n",
      "0 - 1300 13% (0m 41s) 0.1216 (Amanda rodgers? Who ...) / 0 ✓\n",
      "0 - 1400 14% (0m 43s) 0.0821 (What is your best po...) / 0 ✓\n",
      "0 - 1500 15% (0m 50s) 0.0727 (Why is there a week ...) / 0 ✓\n",
      "0 - 1600 16% (0m 58s) 0.0649 (How long does it tak...) / 0 ✓\n",
      "0 - 1700 17% (1m 6s) 0.0761 (How do I design your...) / 0 ✓\n",
      "0 - 1800 18% (1m 11s) 0.0925 (Do you have a shortc...) / 0 ✓\n",
      "0 - 1900 19% (1m 20s) 0.1033 (What are unique fine...) / 0 ✓\n",
      "0 - 2000 20% (1m 29s) 0.0658 (Do you know anyone f...) / 0 ✓\n",
      "0 - 2100 21% (1m 36s) 2.6857 (Why does Hassan Rouh...) / 0 ✗ (1)\n",
      "0 - 2200 22% (1m 44s) 0.0753 (What is the best You...) / 0 ✓\n",
      "0 - 2300 23% (1m 51s) 0.0681 (What do you think ri...) / 0 ✓\n",
      "0 - 2400 24% (1m 59s) 2.8119 (Why don't Nehru, Gan...) / 0 ✗ (1)\n",
      "0 - 2500 25% (2m 6s) 0.0862 (In which industry wo...) / 0 ✓\n",
      "0 - 2600 26% (2m 13s) 2.8135 (Do think like me tha...) / 0 ✗ (1)\n",
      "0 - 2700 27% (2m 18s) 0.0672 (What is digital nonl...) / 0 ✓\n",
      "0 - 2800 28% (2m 21s) 0.0762 (When is KE of pendul...) / 0 ✓\n",
      "0 - 2900 28% (2m 24s) 0.0957 (What is something yo...) / 0 ✓\n",
      "0 - 3000 30% (2m 27s) 0.0742 (What challenges did ...) / 0 ✓\n",
      "0 - 3100 31% (2m 34s) 0.0618 (What does it mean wh...) / 0 ✓\n",
      "0 - 3200 32% (2m 43s) 0.0693 (Why do we use carbon...) / 0 ✓\n",
      "0 - 3300 33% (2m 47s) 0.0774 (Do you push people a...) / 0 ✓\n",
      "0 - 3400 34% (2m 57s) 0.0832 (Which shoes should I...) / 0 ✓\n",
      "0 - 3500 35% (3m 5s) 0.1040 (Who do you think wil...) / 0 ✓\n",
      "0 - 3600 36% (3m 8s) 0.0696 (What is normal body ...) / 0 ✓\n",
      "0 - 3700 37% (3m 16s) 0.0610 (What does it mean wh...) / 0 ✓\n",
      "0 - 3800 38% (3m 19s) 0.0735 (Can anyone say what ...) / 0 ✓\n",
      "0 - 3900 39% (3m 21s) 0.0681 (Which parts of man d...) / 0 ✓\n",
      "0 - 4000 40% (3m 25s) 0.0658 (What is the purpose ...) / 0 ✓\n",
      "0 - 4100 41% (3m 29s) 0.0715 (How do you logout of...) / 0 ✓\n",
      "0 - 4200 42% (3m 32s) 0.0737 (How can I trouble a ...) / 0 ✓\n",
      "0 - 4300 43% (3m 34s) 2.7426 (Why do liberals thin...) / 0 ✗ (1)\n",
      "0 - 4400 44% (3m 37s) 0.0539 (What do you learn in...) / 0 ✓\n",
      "0 - 4500 45% (3m 40s) 0.0752 (What does a CEO and ...) / 0 ✓\n",
      "0 - 4600 46% (3m 45s) 2.8348 (Why do rightists thi...) / 0 ✗ (1)\n",
      "0 - 4700 47% (3m 52s) 0.0657 (What are the various...) / 0 ✓\n",
      "0 - 4800 48% (3m 58s) 0.0548 (Can there be 2 VPs o...) / 0 ✓\n",
      "0 - 4900 49% (4m 1s) 3.0162 (Did England and Fran...) / 0 ✗ (1)\n",
      "0 - 5000 50% (4m 5s) 0.0766 (When will weed get l...) / 0 ✓\n",
      "0 - 5100 51% (4m 7s) 0.0839 (Should Steph McGover...) / 0 ✓\n",
      "0 - 5200 52% (4m 14s) 0.0733 (What are the best eb...) / 0 ✓\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "n_iters = len(dataCSV)\n",
    "print_every = 100\n",
    "plot_every = 1000\n",
    "\n",
    "\n",
    "\n",
    "# Keep track of losses for plotting\n",
    "current_loss = 0\n",
    "all_losses = []\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for epoca in range(0, 10):\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        line = dataCSV.iloc[iter, 1]    \n",
    "        category = dataCSV.iloc[iter, 2]\n",
    "\n",
    "        line_tensor = lineToTensor(dataCSV.iloc[iter, 1])\n",
    "        category_tensor = torch.tensor([category], dtype=torch.long)    \n",
    "\n",
    "\n",
    "        output, loss = train(category_tensor, line_tensor)\n",
    "        current_loss += loss\n",
    "\n",
    "        # Print iter number, loss, name and guess\n",
    "        #if iter % print_every == 0:\n",
    "        if iter % print_every == 0:\n",
    "            guess, guess_i = categoryFromOutput(output)\n",
    "            correct = '✓' if guess == category else '✗ (%s)' % category\n",
    "            print('Epoca %d - %d %d%% (%s) %.4f (%s...) / %s %s' % (epoca, iter, iter / n_iters * 100, timeSince(start), loss, line[:20], guess, correct))\n",
    "\n",
    "        # Add current loss avg to list of losses\n",
    "        if iter % plot_every == 0:\n",
    "            all_losses.append(current_loss / plot_every)\n",
    "            current_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2688c547a90>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(all_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
